{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2024 COMP90042 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the marker, please mention here.*\n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.DataSet Processing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import ijson\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Kaiya\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Kaiya\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Pre-processing \n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "nltk.download('stopwords')\n",
        "stopwords = set(stopwords.words('english'))\n",
        "\n",
        "def lemmatize(word):\n",
        "    lemma = lemmatizer.lemmatize(word, 'v')\n",
        "    if lemma == word:\n",
        "        lemma = lemmatizer.lemmatize(word, 'n')\n",
        "    return lemma\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if text:\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        \n",
        "        words = text.split()\n",
        "        new_words = []\n",
        "        for w in words:\n",
        "            w = lemmatize(w)\n",
        "            if w not in stopwords:\n",
        "                new_words.append(w)\n",
        "        text = \" \".join(new_words)\n",
        "    return text\n",
        "\n",
        "def text_preprocessing(data):\n",
        "    if isinstance(data, str):\n",
        "        return preprocess_text(data)\n",
        "    elif isinstance(data, dict):\n",
        "        data['claim_text'] = preprocess_text(data['claim_text'])\n",
        "        data['evidence_texts'] = [preprocess_text(evidence) for evidence in data['evidence_texts']]\n",
        "        return data\n",
        "    elif isinstance(data, list):\n",
        "        return [text_preprocessing(item) for item in data]\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported data type\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load JSON files\n",
        "def load_json(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
        "        return json.load(file)\n",
        "\n",
        "# Text preprocessing placeholder\n",
        "def preprocess_text(text):\n",
        "    return text  # Implement your actual preprocessing here\n",
        "\n",
        "# Load data\n",
        "train_claims = load_json(\"C:/Users/Kaiya/Desktop/COMP90042_2024-main/data/train-claims.json\")\n",
        "dev_claims = load_json(\"C:/Users/Kaiya/Desktop/COMP90042_2024-main/data/dev-claims.json\")\n",
        "test_claims = load_json(\"C:/Users/Kaiya/Desktop/COMP90042_2024-main/data/test-claims-unlabelled.json\")\n",
        "evidence_dict = load_json(\"C:/Users/Kaiya/Desktop/COMP90042_2024-main/data/evidence.json\")\n",
        "\n",
        "# Process evidence\n",
        "evidence_texts = []\n",
        "evidence_ids = []\n",
        "evidence_index = {}\n",
        "for idx, (evidence_id, evidence_text) in enumerate(evidence_dict.items()):\n",
        "    evidence_ids.append(evidence_id)\n",
        "    evidence_texts.append(preprocess_text(evidence_text))\n",
        "    evidence_index[evidence_id] = idx\n",
        "\n",
        "# Helper function to process claims\n",
        "def process_claims(claims, include_evidences=True):\n",
        "    ids = []\n",
        "    texts = []\n",
        "    labels = []\n",
        "    evidences = []\n",
        "    for claim_id, data in claims.items():\n",
        "        ids.append(claim_id)\n",
        "        texts.append(preprocess_text(data[\"claim_text\"]))\n",
        "        labels.append(data.get(\"claim_label\", None))  # None for test claims\n",
        "        if include_evidences and \"evidences\" in data:\n",
        "            evidences.append([evidence_index[e_id] for e_id in data[\"evidences\"]])\n",
        "        else:\n",
        "            evidences.append([])\n",
        "    return ids, texts, labels, evidences\n",
        "\n",
        "# Process datasets\n",
        "train_ids, train_texts, train_labels, train_evidences = process_claims(train_claims)\n",
        "dev_ids, dev_texts, dev_labels, dev_evidences = process_claims(dev_claims)\n",
        "test_ids, test_texts, _, _ = process_claims(test_claims, include_evidences=False)  # No labels or evidences for test data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1228, 50000)\n",
            "(1208827, 50000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize TfidfVectorizer with max features set to 50,000\n",
        "vectorizer = TfidfVectorizer(max_features=50000, min_df=1)\n",
        "\n",
        "# Fit the vectorizer on the combined corpus of evidence texts, train texts, and test texts\n",
        "combined_corpus = evidence_texts + train_texts + test_texts\n",
        "vectorizer.fit(combined_corpus)\n",
        "\n",
        "# Transform the train, dev, test, and evidence texts into TF-IDF features\n",
        "train_tfidf = vectorizer.transform(train_texts)\n",
        "dev_tfidf = vectorizer.transform(dev_texts)\n",
        "test_tfidf = vectorizer.transform(test_texts)\n",
        "evidence_tfidf = vectorizer.transform(evidence_texts)\n",
        "\n",
        "\n",
        "# Print the shape of the train TF-IDF matrix\n",
        "# This shows the number of documents in the training set and the number of features (terms)\n",
        "print(train_tfidf.shape)\n",
        "\n",
        "# Print the shape of the evidence TF-IDF matrix\n",
        "# This shows the number of evidence documents and the number of features (terms)\n",
        "print(evidence_tfidf.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Calculate cosine similarity between train texts and evidence texts\n",
        "# This computes the cosine similarity for each pair of train and evidence documents\n",
        "train_cos_sims = cosine_similarity(train_tfidf, evidence_tfidf)\n",
        "\n",
        "# Calculate cosine similarity between dev texts and evidence texts\n",
        "# This computes the cosine similarity for each pair of dev and evidence documents\n",
        "dev_cos_sims = cosine_similarity(dev_tfidf, evidence_tfidf)\n",
        "\n",
        "# Calculate cosine similarity between test texts and evidence texts\n",
        "# This computes the cosine similarity for each pair of test and evidence documents\n",
        "test_cos_sims = cosine_similarity(test_tfidf, evidence_tfidf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6777958740499458\n",
            "0.7348484848484849\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to evaluate the performance of a retrieval system using cosine similarity scores\n",
        "def test_retrieval_topk(k, cur_scores, cur_labels):\n",
        "    \"\"\"\n",
        "    Evaluate the retrieval performance by calculating the recall at top-k.\n",
        "\n",
        "    Parameters:\n",
        "    k (int): Number of top results to consider for evaluation.\n",
        "    cur_scores (np.ndarray): Cosine similarity scores.\n",
        "    cur_labels (list of list): True labels (indices of relevant documents) for each query.\n",
        "\n",
        "    Returns:\n",
        "    None: Prints the average recall at top-k.\n",
        "    \"\"\"\n",
        "    ACC = []\n",
        "    for i in range(cur_scores.shape[0]):\n",
        "        # Get the indices of the top-k highest scores for the i-th query\n",
        "        cur_top_ids = np.argpartition(-cur_scores[i], k)[:k]\n",
        "        \n",
        "        # Calculate recall\n",
        "        all_count = len(cur_labels[i])\n",
        "        recall_count = sum(1 for cur_ in cur_labels[i] if cur_ in cur_top_ids)\n",
        "        ACC.append(recall_count / all_count)\n",
        "    \n",
        "    # Print the average recall across all queries\n",
        "    print(sum(ACC) / len(ACC))\n",
        "\n",
        "# Define the top-k value\n",
        "topK = 2000\n",
        "\n",
        "# Evaluate the retrieval performance on training data\n",
        "test_retrieval_topk(topK, train_cos_sims, train_evidences)\n",
        "\n",
        "# Evaluate the retrieval performance on development data\n",
        "test_retrieval_topk(topK, dev_cos_sims, dev_evidences)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reconstruct Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to construct evidence candidates for claims based on cosine similarity scores\n",
        "def construct_evidence_candidates(cos_sims, claim_text_data, claim_evidence_data, evidences_data, candi_num, train_mode=False):\n",
        "    \"\"\"\n",
        "    Construct evidence candidates for claims based on cosine similarity scores.\n",
        "\n",
        "    Parameters:\n",
        "    cos_sims (np.ndarray): Cosine similarity scores.\n",
        "    claim_text_data (list of str): Claim texts.\n",
        "    claim_evidence_data (list of list of int): True evidence indices for each claim.\n",
        "    evidences_data (list of str): Evidence texts.\n",
        "    candi_num (int): Number of candidates to retrieve.\n",
        "    train_mode (bool): Whether the function is in training mode (default: False).\n",
        "\n",
        "    Returns:\n",
        "    tuple: (candis, retrieval_cls_data, retrieval_cls_label)\n",
        "        - candis (list of list of int): Candidate indices for each claim.\n",
        "        - retrieval_cls_data (list of str): Combined claim and evidence texts for classification.\n",
        "        - retrieval_cls_label (list of int): Labels for classification (1 if true evidence, 0 otherwise).\n",
        "    \"\"\"\n",
        "    # Initialize lists to store results\n",
        "    candis = []\n",
        "    retrieval_cls_data = []\n",
        "    retrieval_cls_label = []\n",
        "\n",
        "    for i in range(cos_sims.shape[0]):\n",
        "        if train_mode:\n",
        "            # Add true evidences for training mode\n",
        "            for k in claim_evidence_data[i]:\n",
        "                retrieval_cls_data.append(f\"<cls>{claim_text_data[i]}<sep>{evidences_data[k]}\")\n",
        "                retrieval_cls_label.append(1)\n",
        "            \n",
        "            # Retrieve additional candidates for training, avoiding true evidences\n",
        "            cur_top_ids = np.argsort(-cos_sims[i])[candi_num * 5 : candi_num * 6].tolist()\n",
        "        else:\n",
        "            # Retrieve top-k candidates for evaluation mode\n",
        "            cur_top_ids = np.argpartition(-cos_sims[i], candi_num)[:candi_num].tolist()\n",
        "\n",
        "        candis.append(cur_top_ids)\n",
        "\n",
        "        for j in cur_top_ids:\n",
        "            retrieval_cls_data.append(f\"<cls>{claim_text_data[i]}<sep>{evidences_data[j]}\")\n",
        "            if claim_evidence_data is not None:\n",
        "                retrieval_cls_label.append(1 if j in claim_evidence_data[i] else 0)\n",
        "    \n",
        "    return candis, retrieval_cls_data, retrieval_cls_label\n",
        "\n",
        "# Example usage\n",
        "candi_num = 2000\n",
        "train_mode = True  # or False, depending on your use case\n",
        "\n",
        "# Assuming `train_cos_sims`, `train_texts`, `train_evidences`, and `evidence_texts` are already defined\n",
        "train_candis, train_cls_data, train_cls_labels = construct_evidence_candidates(train_cos_sims, train_texts, train_evidences, evidence_texts, candi_num, train_mode)\n",
        "\n",
        "# Similarly for dev and test datasets\n",
        "dev_candis, dev_cls_data, dev_cls_labels = construct_evidence_candidates(dev_cos_sims, dev_texts, dev_evidences, evidence_texts, candi_num, train_mode=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "dev_topK = 300\n",
        "train_topK = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_candis, train_retrieval_cls_data, train_retrieval_cls_label = construct_evidence_candidates(train_cos_sims, train_texts, train_evidences, evidences_texts, train_topK, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "dev_candis, dev_retrieval_cls_data, dev_retrieval_cls_label = construct_evidence_candidates(dev_cos_sims, dev_texts, dev_evidences, evidences_texts, dev_topK, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_candis, test_retrieval_cls_data, _ = construct_evidence_candidates(test_cos_sims, test_texts, None, evidences_texts, dev_topK, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_retrieval_cls_label = np.array(train_retrieval_cls_label)\n",
        "dev_retrieval_cls_label = np.array(dev_retrieval_cls_label)\n",
        "\n",
        "train_retrieval_cls_data = np.array(train_retrieval_cls_data)\n",
        "dev_retrieval_cls_data = np.array(dev_retrieval_cls_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({0: 613924, 1: 4198})\n",
            "Counter({0: 45957, 1: 243})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "print(Counter(train_retrieval_cls_label))\n",
        "print(Counter(dev_retrieval_cls_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9947402597402597"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "613924/4198\n",
        "\n",
        "45957/243\n",
        "\n",
        "45957 / (45957+243)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Keras Retrieval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=\"<UNK>\")\n",
        "tokenizer.fit_on_texts(train_retrieval_cls_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "225150\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1  # 0 is padding token\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "#tokenise the input into word sequences\n",
        "\n",
        "xseq_train = tokenizer.texts_to_sequences(train_retrieval_cls_data)\n",
        "xseq_dev = tokenizer.texts_to_sequences(dev_retrieval_cls_data)\n",
        "xseq_test = tokenizer.texts_to_sequences(test_retrieval_cls_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "452\n",
            "259\n"
          ]
        }
      ],
      "source": [
        "max_i = 0\n",
        "for i in xseq_train:\n",
        "    max_i = max(max_i, len(i))\n",
        "print(max_i)\n",
        "\n",
        "max_i = 0\n",
        "for i in xseq_dev:\n",
        "    max_i = max(max_i, len(i))\n",
        "print(max_i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padded training sequences:\n",
            "[[   7   29   99 ...    0    0    0]\n",
            " [   7   29   99 ...    0    0    0]\n",
            " [   7   29   99 ...    0    0    0]\n",
            " ...\n",
            " [   7 3787 4634 ...    0    0    0]\n",
            " [   7 3787 4634 ...    0    0    0]\n",
            " [   7 3787 4634 ...    0    0    0]]\n",
            "\n",
            "Padded development sequences:\n",
            "[[   7  211  328 ...    0    0    0]\n",
            " [   7  211  328 ...    0    0    0]\n",
            " [   7  211  328 ...    0    0    0]\n",
            " ...\n",
            " [   7    2 1745 ...    0    0    0]\n",
            " [   7    2 1745 ...    0    0    0]\n",
            " [   7    2 1745 ...    0    0    0]]\n",
            "\n",
            "Padded test sequences:\n",
            "[[   7    2 1860 ...    0    0    0]\n",
            " [   7    2 1860 ...    0    0    0]\n",
            " [   7    2 1860 ...    0    0    0]\n",
            " ...\n",
            " [   7    5 2027 ...    0    0    0]\n",
            " [   7    5 2027 ...    0    0    0]\n",
            " [   7    5 2027 ...    0    0    0]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "# from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "maxlen = 180\n",
        "xseq_train = pad_sequences(xseq_train, padding='post', maxlen=maxlen)\n",
        "xseq_dev = pad_sequences(xseq_dev, padding='post', maxlen=maxlen)\n",
        "xseq_test = pad_sequences(xseq_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "\n",
        "# Pad the sequences\n",
        "xseq_train_padded = pad_sequences(xseq_train, padding='post', maxlen=maxlen)\n",
        "xseq_dev_padded = pad_sequences(xseq_dev, padding='post', maxlen=maxlen)\n",
        "xseq_test_padded = pad_sequences(xseq_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "# Print the padded sequences\n",
        "print(\"Padded training sequences:\")\n",
        "print(xseq_train_padded)\n",
        "\n",
        "print(\"\\nPadded development sequences:\")\n",
        "print(xseq_dev_padded)\n",
        "\n",
        "print(\"\\nPadded test sequences:\")\n",
        "print(xseq_test_padded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2. Model Implementation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZVeNYIH9IaL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefSOe8eTmGP"
      },
      "source": [
        "## Object Oriented Programming codes here\n",
        "\n",
        "*You can use multiple code snippets. Just add more if needed*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "e0144baad0ecee903f108a3e46e51ceadd7da3fc904cfa79747d813b61464b4e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
